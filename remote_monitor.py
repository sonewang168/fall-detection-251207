"""
ğŸ›¡ï¸ æ¨‚é½¡é˜²å‚¾å€’ç›£æ¸¬ç³»çµ± v2.0 - é ç«¯ç›£æ§ç‰ˆ
=======================================
åœ¨çˆ¶æ¯å®¶ä¸­é›»è…¦é‹è¡Œï¼Œä½ å¯ä»¥é ç«¯æŸ¥çœ‹å³æ™‚å½±åƒä¸¦æ¥æ”¶ LINE é€šçŸ¥

åŠŸèƒ½ï¼š
- å³æ™‚å½±åƒä¸²æµï¼ˆç€è¦½å™¨æŸ¥çœ‹ï¼‰
- AI è·Œå€’åµæ¸¬
- LINE é€šçŸ¥ + æˆªåœ–
- Gemini AI åˆ†æ
- å®šæ™‚æˆªåœ–å›å ±

ä½¿ç”¨æ–¹å¼ï¼š
1. å®‰è£å¥—ä»¶ï¼špip install flask opencv-python mediapipe requests --break-system-packages
2. ä¿®æ”¹ä¸‹æ–¹ CONFIG è¨­å®š
3. åŸ·è¡Œï¼špython remote_monitor.py
4. é ç«¯ç€è¦½ï¼šhttp://59.127.52.150:8085
"""

from flask import Flask, Response, render_template_string, jsonify, request
from flask_cors import CORS
import cv2
import mediapipe as mp
import numpy as np
import threading
import time
import requests
import base64
from datetime import datetime

# ==================== è¨­å®šå€ï¼ˆè«‹ä¿®æ”¹é€™è£¡ï¼‰====================
CONFIG = {
    # LINE Bot è¨­å®š
    "line_token": "åœ¨é€™è£¡è²¼ä¸Šä½ çš„ Channel Access Token",
    "line_user_id": "U76a912d913fb2ca1bf85a16ea60e4ad4",
    
    # Gemini AI è¨­å®š
    "gemini_api_key": "åœ¨é€™è£¡è²¼ä¸Šä½ çš„ Gemini API Key",
    
    # ImgBB è¨­å®šï¼ˆæˆªåœ–ä¸Šå‚³ï¼‰
    "imgbb_api_key": "åœ¨é€™è£¡è²¼ä¸Šä½ çš„ ImgBB API Key",
    
    # åµæ¸¬åƒæ•¸
    "angle_threshold": 35,      # å‚¾æ–œè§’åº¦é–¾å€¼
    "frame_threshold": 15,      # é€£çºŒç•°å¸¸å¹€æ•¸
    "cooldown_seconds": 60,     # é€šçŸ¥å†·å»æ™‚é–“ï¼ˆç§’ï¼‰
    
    # å®šæ™‚å›å ±ï¼ˆå°æ™‚ï¼Œ0=é—œé–‰ï¼‰
    "report_interval_hours": 1,
    
    # ä¼ºæœå™¨è¨­å®š
    "host": "0.0.0.0",         # å…è¨±å¤–éƒ¨é€£ç·š
    "port": 8085,              # æ”¹æˆ 8085
    
    # æ”å½±æ©Ÿ
    "camera_index": 0,
}
# ============================================================

app = Flask(__name__)
CORS(app)  # å…è¨±æ‰€æœ‰è·¨åŸŸè«‹æ±‚

# MediaPipe
mp_pose = mp.solutions.pose
pose = mp_pose.Pose(
    static_image_mode=False,
    model_complexity=1,
    smooth_landmarks=True,
    min_detection_confidence=0.5,
    min_tracking_confidence=0.5
)
mp_drawing = mp.solutions.drawing_utils

# å…¨åŸŸè®Šæ•¸
camera = None
is_running = False
current_frame = None
current_status = {"status": "waiting", "angle": 0, "message": "ç­‰å¾…å•Ÿå‹•"}
abnormal_frame_count = 0
last_alert_time = 0
last_report_time = time.time()
initial_head_height = None
head_height_history = []
alert_count = 0
frame_lock = threading.Lock()

# ==================== æ”å½±æ©Ÿèˆ‡åµæ¸¬ ====================
def calculate_torso_angle(shoulder_mid, hip_mid):
    dx = abs(shoulder_mid[0] - hip_mid[0])
    dy = abs(shoulder_mid[1] - hip_mid[1])
    if dy < 0.001:
        return 90
    return np.degrees(np.arctan(dx / dy))

def calculate_head_height(nose_y, hip_y):
    global initial_head_height, head_height_history
    diff = hip_y - nose_y
    head_height_history.append(diff)
    if len(head_height_history) > 30:
        head_height_history.pop(0)
    if initial_head_height is None and len(head_height_history) >= 15:
        initial_head_height = sum(head_height_history[:15]) / 15
    return diff / initial_head_height if initial_head_height else 1

def process_frame(frame):
    global abnormal_frame_count, last_alert_time, current_status, alert_count
    
    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    results = pose.process(rgb_frame)
    
    if not results.pose_landmarks:
        current_status = {"status": "searching", "angle": 0, "message": "ğŸ” æœå°‹ä¸­..."}
        cv2.putText(frame, "Searching...", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)
        return frame
    
    landmarks = results.pose_landmarks.landmark
    h, w = frame.shape[:2]
    
    ls, rs = landmarks[11], landmarks[12]
    lh, rh = landmarks[23], landmarks[24]
    nose = landmarks[0]
    
    if ls.visibility > 0.5 and rs.visibility > 0.5 and lh.visibility > 0.5 and rh.visibility > 0.5:
        shoulder_mid = ((ls.x + rs.x) / 2, (ls.y + rs.y) / 2)
        hip_mid = ((lh.x + rh.x) / 2, (lh.y + rh.y) / 2)
        
        angle = calculate_torso_angle(shoulder_mid, hip_mid)
        head_height = calculate_head_height(nose.y, hip_mid[1])
        
        # ç•«éª¨æ¶
        mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,
            mp_drawing.DrawingSpec(color=(0, 255, 255), thickness=2, circle_radius=3),
            mp_drawing.DrawingSpec(color=(0, 212, 255), thickness=2))
        
        # ç•«è»€å¹¹ä¸­ç·š
        sm_px = (int(shoulder_mid[0] * w), int(shoulder_mid[1] * h))
        hm_px = (int(hip_mid[0] * w), int(hip_mid[1] * h))
        
        is_abnormal = angle > CONFIG["angle_threshold"] or head_height < 0.5
        severity = "danger" if angle > CONFIG["angle_threshold"] * 1.5 or head_height < 0.5 else "warning"
        
        if is_abnormal:
            abnormal_frame_count += 1
            color = (0, 0, 255)
            
            if abnormal_frame_count >= CONFIG["frame_threshold"]:
                now = time.time()
                if now - last_alert_time > CONFIG["cooldown_seconds"]:
                    alert_count += 1
                    threading.Thread(target=trigger_alert, args=(frame.copy(), angle, severity), daemon=True).start()
                    last_alert_time = now
                current_status = {"status": "danger", "angle": angle, "message": f"ğŸš¨ å±éšªï¼{angle:.1f}Â°"}
            else:
                pct = int(abnormal_frame_count / CONFIG["frame_threshold"] * 100)
                current_status = {"status": "warning", "angle": angle, "message": f"âš ï¸ åµæ¸¬ä¸­ {pct}%"}
                color = (0, 165, 255)
        else:
            abnormal_frame_count = max(0, abnormal_frame_count - 2)
            color = (0, 255, 0)
            current_status = {"status": "normal", "angle": angle, "message": f"ğŸ˜Š æ­£å¸¸ {angle:.1f}Â°"}
        
        cv2.line(frame, sm_px, hm_px, color, 6)
        cv2.putText(frame, f"Angle: {angle:.1f}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)
        cv2.putText(frame, f"Head: {head_height:.2f}", (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)
    
    return frame

def camera_thread():
    global current_frame, is_running, camera, last_report_time
    
    camera = cv2.VideoCapture(CONFIG["camera_index"])
    camera.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    camera.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
    
    if not camera.isOpened():
        print("âŒ ç„¡æ³•é–‹å•Ÿæ”å½±æ©Ÿï¼")
        return
    
    print("âœ… æ”å½±æ©Ÿå·²å•Ÿå‹•")
    is_running = True
    
    while is_running:
        ret, frame = camera.read()
        if ret:
            frame = cv2.flip(frame, 1)
            processed = process_frame(frame)
            with frame_lock:
                current_frame = processed.copy()
            
            # å®šæ™‚å›å ±
            if CONFIG["report_interval_hours"] > 0:
                if time.time() - last_report_time > CONFIG["report_interval_hours"] * 3600:
                    threading.Thread(target=send_scheduled_report, args=(frame.copy(),), daemon=True).start()
                    last_report_time = time.time()
        
        time.sleep(0.03)
    
    camera.release()

def generate_frames():
    while True:
        with frame_lock:
            if current_frame is not None:
                ret, buffer = cv2.imencode('.jpg', current_frame, [cv2.IMWRITE_JPEG_QUALITY, 80])
                if ret:
                    yield (b'--frame\r\nContent-Type: image/jpeg\r\n\r\n' + buffer.tobytes() + b'\r\n')
        time.sleep(0.05)

# ==================== é€šçŸ¥åŠŸèƒ½ ====================
def upload_to_imgbb(image):
    if not CONFIG["imgbb_api_key"] or CONFIG["imgbb_api_key"].startswith("åœ¨é€™è£¡"):
        return None
    try:
        _, buffer = cv2.imencode('.jpg', image)
        b64 = base64.b64encode(buffer).decode('utf-8')
        r = requests.post(f"https://api.imgbb.com/1/upload?key={CONFIG['imgbb_api_key']}", data={"image": b64}, timeout=30)
        data = r.json()
        if data.get("success"):
            return data["data"]["url"]
    except Exception as e:
        print(f"ImgBB ä¸Šå‚³å¤±æ•—: {e}")
    return None

def analyze_with_gemini(image):
    if not CONFIG["gemini_api_key"] or CONFIG["gemini_api_key"].startswith("åœ¨é€™è£¡"):
        return "ï¼ˆæœªè¨­å®š Geminiï¼‰"
    try:
        _, buffer = cv2.imencode('.jpg', image)
        b64 = base64.b64encode(buffer).decode('utf-8')
        r = requests.post(
            f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent?key={CONFIG['gemini_api_key']}",
            headers={"Content-Type": "application/json"},
            json={"contents": [{"parts": [
                {"text": "è«‹ç”¨ç¹é«”ä¸­æ–‡ï¼Œç°¡çŸ­åˆ†æï¼ˆ50å­—å…§ï¼‰ç…§ç‰‡ä¸­äººç‰©å§¿æ…‹å®‰å…¨ç‹€æ³ï¼š1.å§¿å‹¢ 2.è·Œå€’é¢¨éšª 3.å»ºè­°"},
                {"inline_data": {"mime_type": "image/jpeg", "data": b64}}
            ]}]},
            timeout=30
        )
        data = r.json()
        if "candidates" in data:
            return data["candidates"][0]["content"]["parts"][0]["text"]
    except Exception as e:
        print(f"Gemini åˆ†æå¤±æ•—: {e}")
    return "ï¼ˆAI åˆ†æå¤±æ•—ï¼‰"

def send_line_message(messages):
    if not CONFIG["line_token"] or CONFIG["line_token"].startswith("åœ¨é€™è£¡"):
        print("âŒ LINE Token æœªè¨­å®š")
        return False
    try:
        r = requests.post(
            "https://api.line.me/v2/bot/message/push",
            headers={"Content-Type": "application/json", "Authorization": f"Bearer {CONFIG['line_token']}"},
            json={"to": CONFIG["line_user_id"], "messages": messages},
            timeout=30
        )
        if r.status_code == 200:
            print("âœ… LINE ç™¼é€æˆåŠŸ")
            return True
        else:
            print(f"âŒ LINE ç™¼é€å¤±æ•—: {r.status_code} {r.text}")
    except Exception as e:
        print(f"âŒ LINE ç™¼é€éŒ¯èª¤: {e}")
    return False

def trigger_alert(frame, angle, severity):
    print(f"ğŸš¨ è§¸ç™¼è­¦å ±ï¼è§’åº¦: {angle:.1f}Â°")
    now = datetime.now().strftime("%Y/%m/%d %H:%M:%S")
    
    messages = []
    
    # ä¸Šå‚³æˆªåœ–
    img_url = upload_to_imgbb(frame)
    if img_url:
        messages.append({"type": "image", "originalContentUrl": img_url, "previewImageUrl": img_url})
    
    # æ–‡å­—è¨Šæ¯
    severity_text = "ğŸš¨ åš´é‡" if severity == "danger" else "âš ï¸ ä¸­åº¦"
    messages.append({
        "type": "text",
        "text": f"ğŸš¨ è·Œå€’è­¦ç¤ºï¼\n\nâ° {now}\nğŸ“ å‚¾æ–œè§’åº¦: {angle:.1f}Â°\nâš¡ ç¨‹åº¦: {severity_text}\n\nè«‹ç«‹å³ç¢ºèªé•·è¼©å®‰å…¨ï¼\n\nğŸ›¡ï¸ æ¨‚é½¡é˜²å‚¾å€’ç³»çµ±"
    })
    
    send_line_message(messages)

def send_scheduled_report(frame):
    print("ğŸ“¸ ç™¼é€å®šæ™‚å›å ±...")
    now = datetime.now().strftime("%Y/%m/%d %H:%M:%S")
    
    messages = []
    
    # ä¸Šå‚³æˆªåœ–
    img_url = upload_to_imgbb(frame)
    if img_url:
        messages.append({"type": "image", "originalContentUrl": img_url, "previewImageUrl": img_url})
    
    # Gemini åˆ†æ
    analysis = analyze_with_gemini(frame)
    
    messages.append({
        "type": "text",
        "text": f"ğŸ“¸ å®šæ™‚ç¾æ³å›å ±\n\nâ° {now}\n\nğŸ¤– AI åˆ†æï¼š\n{analysis}\n\nğŸ›¡ï¸ æ¨‚é½¡é˜²å‚¾å€’ç³»çµ±"
    })
    
    send_line_message(messages)

# ==================== ç¶²é ä»‹é¢ ====================
HTML_TEMPLATE = """
<!DOCTYPE html>
<html lang="zh-TW">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ğŸ›¡ï¸ æ¨‚é½¡å®ˆè­· - é ç«¯ç›£æ§</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body { font-family: -apple-system, sans-serif; background: #0a0a1a; color: white; min-height: 100vh; }
        .container { max-width: 800px; margin: 0 auto; padding: 20px; }
        h1 { text-align: center; background: linear-gradient(135deg, #00d4ff, #7b2cbf); -webkit-background-clip: text; -webkit-text-fill-color: transparent; font-size: 28px; margin-bottom: 10px; }
        .subtitle { text-align: center; color: #888; margin-bottom: 20px; }
        .video-container { position: relative; background: #12122a; border-radius: 20px; overflow: hidden; box-shadow: 0 0 40px rgba(0, 212, 255, 0.2); }
        .video-container img { width: 100%; display: block; }
        .status-bar { display: flex; justify-content: space-between; padding: 15px; background: rgba(0,0,0,0.5); }
        .status { padding: 8px 16px; border-radius: 20px; font-weight: bold; }
        .status.normal { background: #00ff88; color: #000; }
        .status.warning { background: #ffcc00; color: #000; }
        .status.danger { background: #ff3366; color: #fff; animation: pulse 0.5s infinite; }
        .status.searching { background: #00d4ff; color: #000; }
        @keyframes pulse { 0%, 100% { opacity: 1; } 50% { opacity: 0.5; } }
        .info-grid { display: grid; grid-template-columns: repeat(3, 1fr); gap: 15px; margin-top: 20px; }
        .info-card { background: #12122a; border-radius: 15px; padding: 20px; text-align: center; }
        .info-value { font-size: 32px; font-weight: bold; color: #00d4ff; }
        .info-label { font-size: 12px; color: #888; margin-top: 5px; }
        .btn { width: 100%; padding: 15px; border: none; border-radius: 12px; font-size: 16px; font-weight: bold; cursor: pointer; margin-top: 15px; }
        .btn-primary { background: linear-gradient(135deg, #00d4ff, #0099cc); color: white; }
        .btn-danger { background: linear-gradient(135deg, #ff3366, #cc0033); color: white; }
        .config-info { background: #12122a; border-radius: 15px; padding: 20px; margin-top: 20px; font-size: 14px; }
        .config-info h3 { color: #00d4ff; margin-bottom: 10px; }
        .config-item { display: flex; justify-content: space-between; padding: 8px 0; border-bottom: 1px solid #222; }
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸ›¡ï¸ æ¨‚é½¡å®ˆè­·</h1>
        <p class="subtitle">é ç«¯ç›£æ§ç³»çµ± v2.0</p>
        
        <div class="video-container">
            <img src="/video_feed" alt="å³æ™‚å½±åƒ">
            <div class="status-bar">
                <span class="status" id="statusBadge">é€£ç·šä¸­...</span>
                <span style="color: #888;" id="timeDisplay">--:--:--</span>
            </div>
        </div>
        
        <div class="info-grid">
            <div class="info-card">
                <div class="info-value" id="angleValue">--Â°</div>
                <div class="info-label">å‚¾æ–œè§’åº¦</div>
            </div>
            <div class="info-card">
                <div class="info-value" id="alertCount">0</div>
                <div class="info-label">ä»Šæ—¥è­¦ç¤º</div>
            </div>
            <div class="info-card">
                <div class="info-value" id="uptime">--</div>
                <div class="info-label">é‹è¡Œæ™‚é–“</div>
            </div>
        </div>
        
        <button class="btn btn-primary" onclick="sendTestReport()">ğŸ“¸ ç«‹å³å›å ±</button>
        <button class="btn btn-danger" onclick="sendTestAlert()">ğŸ§ª æ¸¬è©¦è­¦å ±</button>
        
        <div class="config-info">
            <h3>âš™ï¸ ç³»çµ±è¨­å®š</h3>
            <div class="config-item"><span>è§’åº¦é–¾å€¼</span><span>{{ angle_threshold }}Â°</span></div>
            <div class="config-item"><span>é€šçŸ¥å†·å»</span><span>{{ cooldown }}ç§’</span></div>
            <div class="config-item"><span>å®šæ™‚å›å ±</span><span>æ¯{{ report_interval }}å°æ™‚</span></div>
            <div class="config-item"><span>LINE é€šçŸ¥</span><span id="lineStatus">æª¢æŸ¥ä¸­...</span></div>
            <div class="config-item"><span>Gemini AI</span><span id="geminiStatus">æª¢æŸ¥ä¸­...</span></div>
            <div class="config-item"><span>ImgBB æˆªåœ–</span><span id="imgbbStatus">æª¢æŸ¥ä¸­...</span></div>
        </div>
    </div>
    
    <script>
        const startTime = Date.now();
        
        function updateStatus() {
            fetch('/api/status')
                .then(r => r.json())
                .then(data => {
                    const badge = document.getElementById('statusBadge');
                    badge.textContent = data.message;
                    badge.className = 'status ' + data.status;
                    document.getElementById('angleValue').textContent = data.angle.toFixed(1) + 'Â°';
                    document.getElementById('alertCount').textContent = data.alert_count;
                    
                    document.getElementById('lineStatus').textContent = data.line_ok ? 'âœ… å·²è¨­å®š' : 'âŒ æœªè¨­å®š';
                    document.getElementById('geminiStatus').textContent = data.gemini_ok ? 'âœ… å·²è¨­å®š' : 'âŒ æœªè¨­å®š';
                    document.getElementById('imgbbStatus').textContent = data.imgbb_ok ? 'âœ… å·²è¨­å®š' : 'âŒ æœªè¨­å®š';
                });
        }
        
        function updateTime() {
            const now = new Date();
            document.getElementById('timeDisplay').textContent = now.toLocaleTimeString('zh-TW');
            
            const elapsed = Math.floor((Date.now() - startTime) / 1000);
            const h = Math.floor(elapsed / 3600);
            const m = Math.floor((elapsed % 3600) / 60);
            document.getElementById('uptime').textContent = h + 'æ™‚' + m + 'åˆ†';
        }
        
        function sendTestReport() {
            fetch('/api/report').then(r => r.json()).then(d => alert(d.message));
        }
        
        function sendTestAlert() {
            fetch('/api/test_alert').then(r => r.json()).then(d => alert(d.message));
        }
        
        setInterval(updateStatus, 1000);
        setInterval(updateTime, 1000);
        updateStatus();
        updateTime();
    </script>
</body>
</html>
"""

@app.route('/')
def index():
    return render_template_string(HTML_TEMPLATE,
        angle_threshold=CONFIG["angle_threshold"],
        cooldown=CONFIG["cooldown_seconds"],
        report_interval=CONFIG["report_interval_hours"] or "é—œé–‰"
    )

@app.route('/video_feed')
def video_feed():
    return Response(generate_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')

@app.route('/api/status')
def api_status():
    return jsonify({
        **current_status,
        "alert_count": alert_count,
        "line_ok": not CONFIG["line_token"].startswith("åœ¨é€™è£¡"),
        "gemini_ok": not CONFIG["gemini_api_key"].startswith("åœ¨é€™è£¡"),
        "imgbb_ok": not CONFIG["imgbb_api_key"].startswith("åœ¨é€™è£¡")
    })

@app.route('/api/report')
def api_report():
    with frame_lock:
        if current_frame is not None:
            threading.Thread(target=send_scheduled_report, args=(current_frame.copy(),), daemon=True).start()
            return jsonify({"status": "ok", "message": "ğŸ“¸ å›å ±å·²ç™¼é€ï¼"})
    return jsonify({"status": "error", "message": "âŒ ç„¡æ³•æ“·å–ç•«é¢"})

@app.route('/api/test_alert')
def api_test_alert():
    with frame_lock:
        if current_frame is not None:
            threading.Thread(target=trigger_alert, args=(current_frame.copy(), 99.9, "danger"), daemon=True).start()
            return jsonify({"status": "ok", "message": "ğŸš¨ æ¸¬è©¦è­¦å ±å·²ç™¼é€ï¼"})
    return jsonify({"status": "error", "message": "âŒ ç„¡æ³•æ“·å–ç•«é¢"})

# ==================== å•Ÿå‹• ====================
if __name__ == "__main__":
    print("=" * 50)
    print("ğŸ›¡ï¸ æ¨‚é½¡é˜²å‚¾å€’ç›£æ¸¬ç³»çµ± v2.0 - é ç«¯ç›£æ§ç‰ˆ")
    print("=" * 50)
    print(f"ğŸ“¡ ä¼ºæœå™¨ä½å€: http://0.0.0.0:{CONFIG['port']}")
    print(f"ğŸŒ é ç«¯å­˜å–: http://59.127.52.150:{CONFIG['port']}")
    print("=" * 50)
    
    # å•Ÿå‹•æ”å½±æ©ŸåŸ·è¡Œç·’
    cam_thread = threading.Thread(target=camera_thread, daemon=True)
    cam_thread.start()
    
    # å•Ÿå‹• Flask
    app.run(host=CONFIG["host"], port=CONFIG["port"], threaded=True, debug=False)
